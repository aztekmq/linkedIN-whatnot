## IBM MQ ML Based Tuning ##

### Introduction: ###

In big computer systems, it's important to make sure everything runs smoothly, like how much the computer's brain (CPU) is working, how much memory is being used, and how full the storage (disk) is. To help with this, we can use machine learning to look at the data collected from the system and find ways to improve how it works. In this project, different parts of the system have different jobs: one part gathers the data, another part does the analysis, and the last part shows the results on a dashboard.

However, this project is more of a proof of concept—meaning it’s like an early version to test ideas, rather than something ready to be sold as a commercial product. It shows how the system might work and could influence the creation of a commercial solution in the future.

### 1. Metrics Collector (Data Gatherer):
What it does: The collector’s job is to gather important data from the computer, like how much of its CPU, memory, and disk space is being used, and send this information to the analysis server.

Things to Keep in Mind: Be Efficient: Since the collector runs on the same computer it’s watching, it should use as little energy as possible so it doesn’t slow things down. It can check the system at regular times or quietly run in the background. Keep the Data Safe: When sending the data to the analysis server, it’s important to use secure methods so no one can steal sensitive information. Handle Errors: If the analysis server is not working, the collector should save any problems it encounters so they can be checked later.

### 2. Analysis Server (Data Analyzer):
What it does: The analysis server looks at the data from the collector, uses machine learning to study it, and then gives advice on how to improve the system’s performance.

Machine Learning Part: Model: The server uses a pre-trained program (server_health_model.h5) to make predictions. You should keep this program updated with new data to make sure it stays accurate. Prepare the Data: Before the analysis, the server checks the data to make sure there aren’t any missing or incorrect numbers that could mess up the results.

Database (SQLite3): Store Results: The server saves the analysis results in a simple database that keeps track of all the past analyses. It should be organized to stay fast as more data gets added. Performance: For smaller amounts of data, SQLite3 is fine. But for bigger systems, you might need a more powerful database like PostgreSQL or MySQL.

### 3. Web Console (User Dashboard):
What it does: The web console is a user-friendly dashboard where people can see charts that show how well the system is running. It also lets users start or stop analyses and look at past results.

Setting it Up: Charts: The web console shows easy-to-read charts about how the system is using its CPU, memory, and disk space, along with recommendations from the analysis server. Filters and Reports: Users can focus on specific time periods or types of data, and download reports for later use if needed. Keep it Secure: Only the right people should be able to access the web console because it contains sensitive system information.

### 4. General Improvements:
Scaling Up: If you need to monitor more computers, the system should be able to handle that. You can expand the collector and the analysis server to manage more data.

Alerts and Notifications: Set up alerts that notify users by email or text if the analysis finds major problems, like low disk space or high CPU usage.

Monitor the System: Make sure both the collector and the analysis server are being monitored to catch any problems with the system itself.

### Final Architecture Overview: ###
+----------------------------+                 +------------------------------+             +------------------------------+
| Linux Server            |                   | Analysis Server         |               | Web Console              |
| (Metrics Collector)|                   | (ML, SQLite, Flask)  |               | (Cube.js Dashboard) |
+---------------------------+                  +------------------------------+             +------------------------------+
                    |                                                               |                                       |
                   V                                                             V                                      V
+-----------------------------------------------------+     +--------------------------------------------------+ 
| Collects CPU, Memory, Disk, Swap,  |      | Receives Data via API,                       |
| Kernel Params, and sends metrics    |      | Runs TensorFlow Analysis,              |
| via HTTP to the Analysis Server.        |      | Stores in SQLite3,                              |
|                                                                      |      | Exposes results to Web Console.  |
+-----------------------------------------------------+     +--------------------------------------------------+ 

This system shows a basic idea of how to split the work into different parts so that everything runs efficiently and securely. It’s not ready to be used as a commercial product, but it’s a good start and could help lead to something more advanced in the future.

github source https://github.com/aztekmq/ibmmq_ml_based_tuning/blob/main/ibmmq_ml_details.md